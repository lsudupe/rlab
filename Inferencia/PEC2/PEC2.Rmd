---
title: "PEC2 Inferencia"
author: "Laura Sudupe Medinilla"
date: "13/1/2021"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo = FALSE, message = FALSE}
# Función para cargar todos los paquetes necesarios
LoadLibraries <- function() {
  myLibraries <- c("foreign","car", "boot")
  invisible(lapply(myLibraries, library, character.only = TRUE))
}

LoadLibraries()
```




# Ejercicio 1. Enunciados teóricos

**a) Se lleva a cabo un estudio para comparar la duración de la estancia hospitalaria de pacientes ingresados con el mismo diagnóstico, en dos hospitales A y B que utilizan dos protocolos de gestión diferentes. En lo dos hospitales A y B se observan los siguientes resultados en estancia para dos grupos de pacientes.• Hospital A | 22, 12, 18, 19, 36, 32, 14, 18, 20, 22.• Hospital B | 26, 32, 33, 38, 24, 27, 19, 29, 30, 26, 24, 16, 28 ¿Hay diferencias en la duración de la estancia entre los 2 hospitales?**

Tenemos variables cuantitativas discretas. Este tipo de datos suele mostrar simetria. Comprobamos la distribución de normalidad con Shapiro-Wilks.
Realizaria un t-test que es un test parametrico para comparar ambos grupos

**b) Para determinar si la refracción esférica ocular es la misma en ambos ojos de los individuos, se midió ésta (en dioptrías) en el ojo derecho y en el izquierdo de 15 personas. Se quiere saber si existen diferencias significativas en la cantidad de dioptrías entre ambos ojos.**

Tenemos dos grupos de variables cualitativas, este tipo de datos suele mostrar simetria. Como en el anterior ejercicio realizaria un Shapiro-Wilk para comprobar distribución de normalidad. A raiz de lo que obtuviera realizaria una prueba parametrica (si acepto Ho) como t-test o no parametrica (si rechazo Ho) como Suma rango de Wilcoxon.

**c) Algunos trabajos han descrito una relación inversa entre el consumo moderado de alcohol y los niveles de colesterol. Para comprobar esta hipótesis, se aplica un cuestionario sobre consumo de alcohol a un grupo de 520 hombres, trabajadores de un polígono industrial. Se obtienen muestras sanguíneas para determinar sus niveles de colesterol. Los sujetos estudiados son clasificados en tres grupos, de acuerdo con el consumo de alcohol manifestado, a saber, “bajo”, “moderado” y “alto”. Se desea averiguar si existen diferencias entre los niveles de colesterol de los grupos estudiados, especificando entre qué grupos se producen las diferencias si es que las hay (Nota: El menor grupo supera los 40 sujetos)**

Por un lado tenemos una variable cuantitativa, que son los niveles de colesterol en sangre, y por otro cualitativa, que son los grupos de consumo de alcohol.
Tenemos dos opciones, por un lado, hacerlo con los datos como estan. En este caso realizariamos un test para comprobar la normalidad y dependiendo del resultado pasariamos a una prueba parametrica o no parametrica para ver si hay diferencias.

Por otro lado, podemos categorizar los datos de los niveles de colesterol entre grupos, tales como Alto y Bajo. En este caso, tendriamos dos grupos de variables cualitativas. Por lo que procederiamos a realizar tablas de contingencias y efectuar un contraste de independencia donde la Ho seria que no existe relación entre las variables. Como el menos grupo supera los 40 sujetos, realizariamos un test chi-cuadrado. 


**d) En el contexto de la pandemia de la COVID-19, numerosos test serológicos han sido propuesto para la detección de anticuerpos Anti-SARS-COV_2. En el laboratorio central del hospital han llegado dos nuevos test de dos empresas biotecnológicas, la A y la B, con las mismas características de sensibilidad y especificidad. El personal del laboratorio central quiere comprobar si ambas pruebas coinciden en los resultados. Para ello quieren efectuar un contraste de hipótesis aplicando los dos test a un grupo de 1200 muestras de suero disponibles. Se desea contrastar si ambos test de antígenos coinciden en el diagnóstico.**

Tenemos dos grupos que queremos comparar en cuestion de porcentajes de coincidencia de diagnostico. Podemos usar un test de comparación de porcentajes como test Z o medir la asociación mediante Chi-cuadrado.


**e) Se plantea un estudio para examinar los efectos exógenos de la Interlukina-33(IL-33) en las característica biológicas del Carcinoma Hepatocellular(HCC). Se clasifica el nivel de la expresión de la IL-33 en Bajo (H-score<68 en 34 pacientes) y Alto(H-score≥68 en 45 pacientes . ). Se desea conocer si por un lado la edad y por otro el volumen del tumor, que es una variable asimétirca, y el tener o no metástasis se asocian con el nivel de IL-33.**

Tenemos una variable cualitativa que es la expresion de IL-33(alto/bajo). Queremos conocer la asociación con tres variables mas, edad (cuantitativa), volumen tumor (cuantitativa) y metastasis (cualitativa).

Lo hariamos a partes, seguramente sean variables no simetricas, comprobariamos la normalidad con las variables respuesta mediante test Shapiro-Wilk. Por un lado respecto las variables cuantitativas realizariamos una prueba no-parametrica que compare distribuciones como Kruskal-Wallis. Podemos comparar si las parejas son diferentes con el test Dunn.

En cuanto la variable cualitativa, metastasis, habria que compararlo con un prueba de asociación como chi-cuadrado.


# Ejercicio 2. Ejercicio práctico

**Se dispone de 1092 pacientes mayores de 65 años que fueron ingresados en un hospital por tres patologías(tipocas): síndrome coronario agudo (SCA), accidente cerebrovascular (AVC) y Neumonía(Neumo). Los sujetos fueron asignados a dos grupos: Los casos y controles en función de un tratamiento preventivo recibido(caso). Se midieron algunas variables como el sexo , la edad, antecedentes de cardiopatía y diabetes. Además se disponía de la tensión arterial sistólica(TAS) y el índice de Barthel que es una escala de autonomía del paciente.**

Selecciona 900 casos al azar del fichero para generar la base datos del trabajo
```{r}
(set.seed(99991)) # Sustituye ###### por un número

dades <- as.data.frame(read.dta("data_admission.dta"))

dades900 <- dades[sample(1:nrow(dades),900,replace=FALSE),]

```

Las preguntas

Antes de comenzar con las preguntas, vamor a realizar un breve estudio de los datos

```{r}
summary(dades900)
```


**1) ¿ Existe asociación entre el tener una cardiopatía previa y el tipo de enfermedad por la que ingresó el paciente ? ¿Y con tener diabetes y el tipo de enfermedad por la que ingresó el paciente ?**

Tenemos dos grupos de variables cualitativas, por lo tanto efectuaremos una tabla de contingencia y un contraste de independencia. 

```{r}
#cardiopatía previa y tipo de enfermedad
dfcardio <- with(dades900, table(dades900$cardiopatia, dades900$tipocas))
addmargins(dfcardio)
prop.table(dfcardio,1)
```


```{r}
#diabetes y tipo de enfermedad
dfdiabetes <- with(dades900, table(dades900$diabetes, dades900$tipocas))
addmargins((dfdiabetes))
prop.table(dfdiabetes,1)
```
Para ver si existe asociación entre las variables, usaremos el test Chi-cuadrado teniendo en cuenta que la hipotesis nula es que no existe relación.

```{r}
chisq.test(dfcardio)
chisq.test(dfdiabetes)
```
En cuanto a la relación entre cardiopatia previa y tipo de enfermedad de ingreso, obtenemos un p-value por debajo de 0.05, por lo tanto, rechazamos la hipotesis nula de que no hay relación entre las variables. Hay asociación entre la cardiopatia previa y el tipo de enfermedad.

En cambio, si observamos el p-value obtenido para la variable de diabetes y tipo de enfermedad, es mayor que 0.05, aceptando entonces la hipotesis nula, no existe asociación entre las variables.


**2) Comprueba la normalidad de las variables tensión arterial(TAS) y score de Barthel.**

Ambas variables son cuantitativas, podemos comprobar la normalidad mediante el test de Shapiro-Wilk en donde la hipotesis nula es que presenta normalidad
```{r}
#Tensión arterial
shapiro.test(dades900$tas)

#Score de Barthel
shapiro.test(dades900$barthel)
```
En ambos casos el test nos da un valor p menos que 0.05, por lo tanto descartamos la normalidad.




**3)¿Existe asociación entre la TAS y el tipo de enfermedad por el que ingreso el paciente? ¿Y entre el score de Barthel y el tipo de Caso?**

En este caso, vamos a comparar si hay asociación entre una variable cuantitativa (TAS) y una variable cualitativa (tipo de enfermedad).

Vamos a comprobar la normalidad de cada grupo mediante los graficos qq plot y un diagrama de cajas
```{r}

with(dades900, qqnorm(tas[tipocas== "SCA"], main= "Normal QQplot Tipo de enfermedad, SCA"))
with(dades900, qqline(tas[tipocas=="SCA"]))

with(dades900, qqnorm(tas[tipocas== "ACV"], main= "Normal QQplot Tipo de enfermedad, ACV"))
with(dades900, qqline(tas[tipocas=="ACV"]))

with(dades900, qqnorm(tas[tipocas== "Neumo"], main= "Normal QQplot Tipo de enfermedad, Neumo"))
with(dades900, qqline(tas[tipocas=="Neumo"]))
```

```{r}
with(dades900, boxplot(tas~tipocas))

```
En los tres grupos, los extremos se alejan de la recta de normalidad, pero el diagrama de cajas nos muestra que tenemos una distribución simetrica. Comprobaremos la normalidad con el test Shapiro-Wilk
```{r}
with(dades900, shapiro.test(tas[tipocas=="SCA"]))
with(dades900, shapiro.test(tas[tipocas=="ACV"]))
with(dades900, shapiro.test(tas[tipocas=="Neumo"]))
```
En todas obtenemos que los test son significativos y descartamos la normalidad. Tenemos un tamaño grande de muestra y la media es buena medida descriptiva. Como no tenemos una distribución normal, para ver la asociación vamos a usar un test no-parametrico. Estaremos asumiendo como hipotesis nula que la distribución de TAS en los tres grupos es la misma. Realizaremos la prueba Kruskal-Wallis . Si quisieramos hacer un test parametrico, realizariamos ANOVA. Comprobariamos la homogeneidad de las varianzas con Levene.
```{r}
with(dades900, kruskal.test(tas~tipocas))
```
Tenemosun valor significativo, por lo tanto descartamos la hipotesis nula. Consideramos que si hay asociación entre la presión arterial histolica y las patologias previas.

Vamos a comprobar si existe asociación entre el índice de Barthel y la patologia previa.

Como antes, vamos a comprobar la normalidad de cada grupo mediante los graficos qq plot y un diagrama de cajas
```{r}

with(dades900, qqnorm(barthel[tipocas== "SCA"], main= "Normal QQplot Tipo de enfermedad, SCA"))
with(dades900, qqline(barthel[tipocas=="SCA"]))

with(dades900, qqnorm(barthel[tipocas== "ACV"], main= "Normal QQplot Tipo de enfermedad, ACV"))
with(dades900, qqline(barthel[tipocas=="ACV"]))

with(dades900, qqnorm(barthel[tipocas== "Neumo"], main= "Normal QQplot Tipo de enfermedad, Neumo"))
with(dades900, qqline(barthel[tipocas=="Neumo"]))
```
Estos graficos estan lejos de la normalidad, vamos a ver que nos muestra la representación de cajas

```{r}
with(dades900, boxplot(barthel~tipocas))
```
Tenemos demasiados outliers. 

```{r}
with(dades900, shapiro.test(barthel[tipocas=="SCA"]))
with(dades900, shapiro.test(barthel[tipocas=="ACV"]))
with(dades900, shapiro.test(barthel[tipocas=="Neumo"]))
```

Como era de esperar, descartamos la hipotesis nula de una distribución normal. Teniendo en cuenta los resultado
en este caso tambien vamos a usar un test no-parametrico .
```{r}
with(dades900, kruskal.test(barthel~tipocas))
```
Es significativo, descartamos la hipotesis nula, consideramos que si hay asociación entre el indice de autonomia y el tipo de patologia previa.


**4)¿Existe asociación entre la TAS y el ser caso o control? ¿Y entre el Barthel y el ser caso o control?**

Vamos a ver si hay asociación entre la variable cuantitativa TAS (presión arterial sistólica) y la variable cualitativa ser caso o control. Como en los casos anteriores, procederemos a ver realizar los graficos QQ-plot para ver si muestra normalidad, los graficos boxplot para ver la simetria y un Shapiro test para ver si se mantiene la hipotesis nula de que hay una distribución normal. A partir de estos resultados, determinaremos si hay que hacer una prueba de contraste parametrica o no-parametrica
```{r}
with(dades900, qqnorm(tas[caso== "Control"], main= "Normal QQplot caso: control"))
with(dades900, qqline(tas[caso=="Control"]))

with(dades900, qqnorm(tas[caso== "Caso"], main= "Normal QQplot caso: caso"))
with(dades900, qqline(tas[caso=="Caso"]))

with(dades900, boxplot(tas~caso))
```
```{r}
#test Shapiro
with(dades900, shapiro.test(tas[caso=="Control"]))
with(dades900, shapiro.test(tas[caso=="Caso"]))
```
En ambos casos descartamos la hipotesis nula de normalidad. Hemos visto en las graficas, que la media es un buen descriptor, y dado que tenemos un tamaño suficientemente grande, realizaremos un test no-parametrico.
Comprobaremos la igualdad de varianzas.
```{r}
with(dades900,leveneTest(tas~caso ))
```
Tenemos un valor p mayor que 0.05 con lo cual no rechazamos la hipotesis nula de igualdad de varianzas y utilizaremos un t-test de varianzas iguales
```{r}
with(dades900,t.test(tas~caso,var.equal=TRUE ))
```
Un valor p menor que 0.05, con lo cual rechazamos la hipotesis de igualdad de medias de la presión arterial sistolica entre los grupos de caso y control. Realizaremos el test de Suma-rango de Wilcoxon
```{r}
with(dades900,wilcox.test(tas~caso))
```

Rechazamos la hipotesis nula de no diferencias. Hay asociación entre las distribuciones.

A continuación veremos si hay asociación entre la variable cuantitativa Barthel y ser caso o control. El procedimiento a seguir es el mismo.
```{r}
with(dades900, qqnorm(barthel[caso== "Control"], main= "Normal QQplot caso: control"))
with(dades900, qqline(barthel[caso=="Control"]))

with(dades900, qqnorm(barthel[caso== "Caso"], main= "Normal QQplot caso: caso"))
with(dades900, qqline(barthel[caso=="Caso"]))

with(dades900, boxplot(barthel~caso))
```

Los valores se alejan de la recta de normalidad y la simetria no es la adecuada. Realizaremos test Shapiro para normalidad, ademas hay muchos outliers.
```{r}
#test Shapiro
with(dades900, shapiro.test(barthel[caso=="Control"]))
with(dades900, shapiro.test(barthel[caso=="Caso"]))
```
Ambas tienen un resultado significativo, rechazamos hipotesis nula de distribución normal. Vamos a relizar un test no-parametrico.
```{r}
with(dades900,wilcox.test(barthel~caso))
```
tenemos un valor p por encima de 0.05, no rechazamos la hipotesis nula. Por lo tanto, consideramos que no hay asociación



Selecciona 40 casos al azar de la base de datos

**5)¿ Existe asociación entre la TAS y el ser caso o control ? ¿ y entre el Barthel y el ser caso o control ?**

Realizaremos el mismo procedimiento que en el punto 4. Vamos a ver si el tamaño de la muestra nos da valores diferentes en los test.
```{r}
set.seed(9991)
dades40 <- dades[sample(1:nrow(dades),40,replace=FALSE),]
```

Vamos a realizar las graficas QQ-plot y la grafica de cajas
```{r}
with(dades40, qqnorm(tas[caso== "Control"], main= "Normal QQplot caso: control"))
with(dades40, qqline(tas[caso=="Control"]))

with(dades40, qqnorm(tas[caso== "Caso"], main= "Normal QQplot caso: caso"))
with(dades40, qqline(tas[caso=="Caso"]))

with(dades40, boxplot(tas~caso))
```


```{r}
#test Shapiro
with(dades40, shapiro.test(tas[caso=="Control"]))
with(dades40, shapiro.test(tas[caso=="Caso"]))
```
En ambos casos no descartamos la hipotesis nula, cosideramos que hay normalidad. Por lo tanto, realizaremos una prueba parametrica. Al haber 2 grupos no realizaremos ANOVA. Realizarmos la prueba t-test. Comprobamos la homogeneidad de varianzas con Levene
```{r}
with(dades40,leveneTest(tas~caso ))
```
Tenemos un valor p mayor que 0.05 con lo cual no rechazamos la hipotesis nula de igualdad de varianzas y utilizaremos un t-test de varianzas iguales ya que asumimos normalidad.
```{r}
with(dades40,t.test(tas~caso,var.equal=TRUE ))
```
p value mayor que 0.05, no rechazamos la hipotesis de igualdad de medias. Asumimos no hay diferencias de presión sistolica segun el grupo al que pertenece.

En cuanto a la variable cuantitativa barthel
```{r}
with(dades40, qqnorm(barthel[caso== "Control"], main= "Normal QQplot caso: control"))
with(dades40, qqline(barthel[caso=="Control"]))

with(dades40, qqnorm(barthel[caso== "Caso"], main= "Normal QQplot caso: caso"))
with(dades40, qqline(barthel[caso=="Caso"]))

with(dades40, boxplot(barthel~caso))
```
No se ajusta la normalidad a la linea. Hay simetria pero muchos outliers y no es una muestra grande.

```{r}
#test Shapiro
with(dades40, shapiro.test(barthel[caso=="Control"]))
with(dades40, shapiro.test(barthel[caso=="Caso"]))
```
En ambos casos tenemos p-value significativo, rechazamos hipotesis nula de normalidad. Realizamos prueba parametrica. Elegimos el test Wilcoxon porque tenemos 2 grupos
```{r}
with(dades40,wilcox.test(barthel~caso))
```
No parece que haya diferencias entre la escala de autonomia del paciente y ser del grupo caso o control.



# Ejercicio 3. Algunas cosas más

**a) Indica para que te podrían servir las técnicas de bootstrap en los análisis estadísticos que has realizado. Calcula el intervalo utilizando Bootstrap de la mediana de la tensión arterial**

El metodo bootstrap asigna medidas de precision(sesgo, varianza, intervalos de confianza..) a las estimaciones de muestra. Con esto, se puede estimar la distribución muestral de casi cualquier estadistica utilizando metodos de muestreo aleatorio. Srive tambien para construir pruebas de hipotesis, si la inferencia estadistica basada en la suposicion de un modelo parametrico esta en duda, se puede usar como alternativa. Tambien cuando la inferencia parametrica es imposible o requiere formulas complicadas para calculo de errores estandar.

En nuestro caso, si tenemos suposiciones que estan en duda, seria un metodo alternativo a usar.

Vamos a calcular el intervalo utilizando Bootstrap de la mediana de la tensión arterial

```{r}
a <- c(dades$tas)
dfbootstrap <- data.frame(a)

boot.mean=function(dfbootstrap,indices) 
  mean(dfbootstrap[indices],na.rm=TRUE)
mx=boot(dfbootstrap$a,boot.mean,2000)
boot.ci(mx)
```

**b) Indica porqué hay que utilizar técnicas de comparacion múltiple como la corrección de Bonferroni**

El valor de o representa la probabilidad de que la diferencia observada se deba al azar. Nos conformamos con el riesgo de error del 5% que llamamos error tipo I, rechazando la hipotesis nula cuando es cierta y la diferencia se debe al azar.

Cuando comparamos las medias de mas de dos muestras la cosa se complica, y recurrimos al analisis de la varianza (si las muestras se distribuyen de forma normal y sus varianzas son iguales), asi obtenemos un valor p, realizamos una prueba de contraste y vamos haciendo comparaciones dependiendo la cantidad de grupos. Sin embargo, cuanto mayor es el numero de comparaciones, mayor es el riesgo de meter la pata. Al hacer cada contraste, la probabilidad de un significativo es de 0.05 y la de un no significativo de 0.95. Si hacemos 30 comparaciones independientes, la probabilidad de que ninguno sea significativo sera de 0.95 x 30, haciendo con esto que el error de tipo I aumente. ¿La solución? la corrección de Bonferroni. 

Es un metodo  para considerar diferencias estadisticamente significativas entre muchos grupos sin aumentar el riesgo de error de tipo I.

